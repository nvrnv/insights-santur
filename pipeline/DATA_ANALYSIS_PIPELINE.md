# üîÑ Data Analysis Pipeline –¥–ª—è HR-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π

## üìã –û–±–∑–æ—Ä –ø–∞–π–ø–ª–∞–π–Ω–∞

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º –∏ –∏–Ω—Å–∞–π—Ç–æ–≤.

---

## üóÇÔ∏è –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### üìÅ –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
```
results_to_work_with/
‚îú‚îÄ‚îÄ –§–∞–±—Ä–∏–∫–∞-–Æ–º–∞—à–µ–≤–∞_–ü–æ–≤–∞—Ä–∞_–†—É—Å—Å–∫–∏–π_gg_3_0001.txt
‚îú‚îÄ‚îÄ –§–∞–±—Ä–∏–∫–∞-–Æ–º–∞—à–µ–≤–∞_–ü–æ–≤–∞—Ä–∞_–ö–∏—Ä–≥–∏–∑—Å–∫–∏–π_gg_12_0022.txt
‚îú‚îÄ‚îÄ –ê–£–ü-–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞_–†—É—Å—Å–∫–∏–π_gg_6_0005.txt
‚îî‚îÄ‚îÄ ... (–≤—Å–µ–≥–æ 186 —Ñ–∞–π–ª–æ–≤ –∏–Ω—Ç–µ—Ä–≤—å—é)
```

### üèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤
- **–§–æ—Ä–º–∞—Ç –∏–º–µ–Ω–∏**: `{–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç}_{–Ø–∑—ã–∫}_{ID}.txt`
- **–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ**: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã –∏–Ω—Ç–µ—Ä–≤—å—é –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
- **–Ø–∑—ã–∫–∏**: –†—É—Å—Å–∫–∏–π, –ö–∏—Ä–≥–∏–∑—Å–∫–∏–π, –ê–Ω–≥–ª–∏–π—Å–∫–∏–π, –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π, –£–∑–±–µ–∫—Å–∫–∏–π

---

## üîç –≠—Ç–∞–ø 2: –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (Broad Scope Analysis)

### üéØ –¶–µ–ª—å
–í—ã—è–≤–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—â–µ –≤—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ –∏–Ω—Ç–µ—Ä–≤—å—é

### üõ†Ô∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
- **–ú–µ—Ç–æ–¥**: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
- **–Ø–∑—ã–∫**: Python 3
- **–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏**: `re`, `json`, `pathlib`

### üìä –ü—Ä–æ—Ü–µ—Å—Å
```python
# –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
def broad_scope_analysis(text_files):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º
    """
    topics = {}
    for file in text_files:
        content = read_file(file)
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —à–∏—Ä–æ–∫–∏–π –Ω–∞–±–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–º
        detected_topics = extract_topics(content)
        update_topic_frequency(topics, detected_topics)
    
    return rank_topics_by_frequency(topics)
```

### üìà –†–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∞–ø–∞ 2
- –°–ø–∏—Å–æ–∫ —Ç–æ–ø-10 —Ç–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
- –ü–µ—Ä–≤–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–π —Ç–µ–º—ã
- –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞–º –∏ —è–∑—ã–∫–∞–º

---

## üéØ –≠—Ç–∞–ø 3: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–µ–º–∞–º (Topic-Specific Analysis)

### üî¨ –¶–µ–ª—å
–î–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—É—é –≤—ã—è–≤–ª–µ–Ω–Ω—É—é —Ç–µ–º—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫

### üìã –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —Å–æ–∑–¥–∞–µ–º:

#### üõ†Ô∏è –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
```python
def analyze_specific_topic(topic_name, search_patterns):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ç–µ–º—É –≤–æ –≤—Å–µ—Ö –∏–Ω—Ç–µ—Ä–≤—å—é
    
    Args:
        topic_name: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ó–∞–¥–µ—Ä–∂–∫–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã")
        search_patterns: –°–ø–∏—Å–æ–∫ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
    
    Returns:
        –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ü–∏—Ç–∞—Ç–∞–º–∏
    """
    results = {
        "topic": topic_name,
        "total_files": 0,
        "files_with_mentions": 0,
        "total_mentions": 0,
        "department_breakdown": {},
        "language_breakdown": {},
        "quotes_with_context": []
    }
    
    for file_path in all_interview_files:
        mentions = find_topic_mentions(file_path, search_patterns)
        if mentions:
            update_results(results, file_path, mentions)
    
    return results
```

#### üîç –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã
```python
# –ü—Ä–∏–º–µ—Ä –¥–ª—è —Ç–µ–º—ã "–ó–∞–¥–µ—Ä–∂–∫–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã"
salary_delay_patterns = [
    r'–∑–∞–¥–µ—Ä–∂\w*\s+–∑–∞—Ä–ø–ª–∞—Ç\w*',
    r'–∑–∞—Ä–ø–ª–∞—Ç\w*\s+–∑–∞–¥–µ—Ä–∂\w*',
    r'–Ω–µ\s+–≤—ã–ø–ª–∞—á\w*\s+–≤–æ–≤—Ä–µ–º—è',
    r'–≤—ã–ø–ª–∞—Ç\w*\s+—á–∞—Å—Ç\w*',
    # ... –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
]

# –ü—Ä–∏–º–µ—Ä –¥–ª—è —Ç–µ–º—ã "–£—Å–ª–æ–≤–∏—è —Ç—Ä—É–¥–∞"
work_conditions_patterns = [
    r'—É—Å–ª–æ–≤–∏—è\s+—Ç—Ä—É–¥–∞',
    r'—Ä–∞–±–æ—á\w*\s+–º–µ—Å—Ç\w*',
    r'—Ç—è–∂–µ–ª\w*\s+—Ä–∞–±–æ—Ç\w*',
    r'—Ä–∞–∑–¥–µ–≤–∞–ª–∫\w*',
    # ... –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
]
```

---

## üìä –≠—Ç–∞–ø 4: –°–±–æ—Ä –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### üóÉÔ∏è –í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã
```json
{
  "topic": "–ó–∞–¥–µ—Ä–∂–∫–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã",
  "total_files": 186,
  "files_with_mentions": 20,
  "percentage_interviews": 10.8,
  "total_mentions": 32,
  "department_breakdown": {
    "–§–∞–±—Ä–∏–∫–∞ –Æ–º–∞—à–µ–≤–∞": 11,
    "–§–∞–±—Ä–∏–∫–∞ –©–µ—Ä–±–∞–∫–æ–≤–∞": 8,
    "–ê–£–ü –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞": 1
  },
  "representative_quotes": [
    {
      "quote": "–ó–∞–¥–µ—Ä–∂–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è...",
      "source": "–§–∞–±—Ä–∏–∫–∞-–Æ–º–∞—à–µ–≤–∞_–ü–æ–≤–∞—Ä–∞_–†—É—Å—Å–∫–∏–π_gg_3_0003.txt",
      "department": "–§–∞–±—Ä–∏–∫–∞ –Æ–º–∞—à–µ–≤–∞ - –ü–æ–≤–∞—Ä–∞"
    }
  ]
}
```

---

## üîÑ –≠—Ç–∞–ø 5: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è

### ‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
```python
def compare_with_baseline(original_data, analyzed_data):
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    comparison = []
    for topic in original_data:
        original_percentage = topic['percentage']
        actual_percentage = analyzed_data[topic['name']]['percentage_interviews']
        discrepancy = actual_percentage - original_percentage
        
        comparison.append({
            "topic": topic['name'],
            "original_claim": original_percentage,
            "actual_findings": actual_percentage,
            "discrepancy": discrepancy,
            "status": classify_discrepancy(discrepancy)
        })
    
    return comparison
```

### üìà –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞
- –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ç–µ–º –ø–æ —Ä–µ–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
- –í—ã—è–≤–ª–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–µ—Ä–µ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∏ –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–º
- –ë–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
gurman-insights/
‚îú‚îÄ‚îÄ results_to_work_with/           # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (186 –∏–Ω—Ç–µ—Ä–≤—å—é)
‚îú‚îÄ‚îÄ analysis/                       # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
‚îÇ   ‚îú‚îÄ‚îÄ salary_delays_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ work_conditions_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ team_atmosphere_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ management_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ work_processes_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ canteen_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ locker_rooms_sanitary_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ career_development_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ quality_control_fines_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ work_uniform_clothes_analysis.json
‚îÇ   ‚îî‚îÄ‚îÄ complete_topics_analysis.json
‚îú‚îÄ‚îÄ scripts/                        # –°–∫—Ä–∏–ø—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
‚îÇ   ‚îú‚îÄ‚îÄ analyze_salary_delays.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_work_conditions.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_team_atmosphere.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_management.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_work_processes.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_canteen.py
‚îÇ   ‚îî‚îÄ‚îÄ analyze_all_remaining.py
‚îî‚îÄ‚îÄ DATA_ANALYSIS_PIPELINE.md       # –≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç
```

---

## üõ†Ô∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### üìö –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```python
import os
import json
import re
from pathlib import Path
from typing import Dict, List, Tuple
```

### üîß –ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

#### 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
```python
def extract_metadata(filename):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç, —è–∑—ã–∫ –∏ ID –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    """
    parts = filename.replace('.txt', '').split('_')
    return {
        'department': parts[0].replace('-', ' '),
        'language': parts[2] if len(parts) > 2 else "Unknown",
        'file_id': parts[-1]
    }
```

#### 2. –ü–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
```python
def find_mentions_with_context(content, patterns, context_size=60):
    """
    –ù–∞—Ö–æ–¥–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    """
    mentions = []
    for pattern in patterns:
        matches = re.finditer(pattern, content, re.IGNORECASE | re.UNICODE)
        for match in matches:
            start = max(0, match.start() - context_size)
            end = min(len(content), match.end() + context_size)
            context = content[start:end].strip()
            
            mentions.append({
                "pattern": pattern,
                "match": match.group(),
                "context": context,
                "position": match.start()
            })
    return mentions
```

#### 3. –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
```python
def calculate_metrics(analysis_results):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞
    """
    total_files = analysis_results["total_files"]
    files_with_mentions = analysis_results["files_with_mentions"]
    
    percentage = round((files_with_mentions / total_files) * 100, 1)
    
    return {
        "percentage_interviews": percentage,
        "coverage": f"{files_with_mentions}/{total_files}",
        "mention_density": analysis_results["total_mentions"] / files_with_mentions if files_with_mentions > 0 else 0
    }
```

---

## üìä –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

### üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
- **–ü—Ä–æ—Ü–µ–Ω—Ç –∏–Ω—Ç–µ—Ä–≤—å—é —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏**: –î–æ–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é, –≥–¥–µ —Ç–µ–º–∞ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è —Ö–æ—Ç—è –±—ã —Ä–∞–∑
- **–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π**: –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Ç–µ–º–∞ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤–æ –≤—Å–µ—Ö –∏–Ω—Ç–µ—Ä–≤—å—é
- **–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–π**: –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
- **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞–º**: –í –∫–∞–∫–∏—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è—Ö —Ç–µ–º–∞ –Ω–∞–∏–±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª—å–Ω–∞
- **–Ø–∑—ã–∫–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ**: –ù–∞ –∫–∞–∫–∏—Ö —è–∑—ã–∫–∞—Ö —Ç–µ–º–∞ –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è —á–∞—â–µ

### üìà –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- **–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏**: –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –∑–∞—è–≤–ª–µ–Ω–Ω—ã–º–∏ –∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏
- **–†–∞–Ω–≥–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è**: –ö–∞–∫ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –ø–æ–∑–∏—Ü–∏—è —Ç–µ–º—ã –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ
- **–°—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: –ü–µ—Ä–µ–æ—Ü–µ–Ω–µ–Ω–∞, –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–∞ –∏–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞

---

## üöÄ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞

### üîÑ –î–ª—è –Ω–æ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤:

1. **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**
   - –°–æ–±—Ä–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
   - –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
   - –û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫

2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**
   - –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∏—Å–∫–∞ –ø–æ–¥ —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –ø—Ä–æ–µ–∫—Ç–∞
   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ–º—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
   - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã, —è–∑—ã–∫–∏, etc.)

3. **–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞**
   - –í—ã–ø–æ–ª–Ω–∏—Ç—å —à–∏—Ä–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —Ç–µ–º
   - –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–∞–∂–¥–æ–π —Ç–µ–º–µ
   - –°–æ–±—Ä–∞—Ç—å –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

4. **–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**
   - –°—Ä–∞–≤–Ω–∏—Ç—å —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –≥–∏–ø–æ—Ç–µ–∑–∞–º–∏
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ü–∏—Ç–∞—Ç
   - –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤—ã–±–æ—Ä–∫–µ

---

## ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### üö® –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö –∏ –º–æ–∂–µ—Ç –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
- –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
- –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –†–µ–≥—É–ª—è—Ä–Ω–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É –¥–ª—è –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –ø–æ–∏—Å–∫–∞
- –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

---

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞–π–ø–ª–∞–π–Ω–∞ –∏–ª–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ–¥ –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –∫–æ–º–∞–Ω–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.

---

*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 28 —Å–µ–Ω—Ç—è–±—Ä—è 2025*
